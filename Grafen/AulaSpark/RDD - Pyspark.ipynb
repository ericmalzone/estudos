{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD: resilient distributed dataset\n",
    "\n",
    "* Resilient: os dados perdidos na memória podem ser recriados\n",
    "* Distributed: dados separados atráves do cluster\n",
    "* Data Set: entrada pode ser qualquer tipo de origem\n",
    "\n",
    "RDDs são a unidade fundamental do Spark, são imutáveis. Podem ser criados de três formas:\n",
    "\n",
    "* De um arquivo ou conjunto de arquivos;\n",
    "* De dados na memória;\n",
    "* De outro RDD;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark\n",
    "#findspark.init()\n",
    "\n",
    "#Deixei comentado as 2 linhas acima porque na forma que eu instalei não precisa\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem três formas de criar um RDD:\n",
    "\n",
    "    1. De um arquivo ou conjunto de arquivos;\n",
    "    2. De dados na memória\n",
    "    3. De outro rdd\n",
    "    \n",
    "Utilizamos o método **.textFile()** para carregar arquivos em uma aplicação spark. Seu retorno é um RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('sobreRDD.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método **.collect()** é responsável por passar os dados do RDD ao drive e apresenta-los para o usuário, seu uso é *custoso*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método **.filter** que aprendemos em python também é utilizado em RDD's, para isso usamos a função **lambda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando funcao .filter(), mesmo conceito que usamos em python, aplicando a funcao lambda.\n",
    "rddsparklinhas = rdd.filter(lambda linha: 'spark' in linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .collect() para exibir o resultado\n",
    "rddsparklinhas.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método **first()** pode nos auxiliar exibindo a primeira linha. Observação: não é possível selecionar quantas linhas apresentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E para exibir a quantidade de linhas dentro do RDD, utilizamos o método **.count()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDD com 2 \"colunas\"\n",
    "sc.parallelize([(1,2),(3,4)]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação e Ação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformações básicas em um RDD. Contendo: {1, 2, 3, 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome da função | Propósito | Exemplo | Resultado\n",
    "---- | ----\n",
    "```.map()``` | Aplica a função para cada elemento no RDD, seu retorno é outro RDD. | rdd.map(lambda x: x + 1) | {2, 3, 4, 4}\n",
    "```.flatMap()``` | Aplica a função para cada elemento no RDD, seu retorno é outro RDD. | rdd.flatMap(lambda x: range(x, 4)) | {1, 2, 3, 2, 3, 3, 3}\n",
    "```.filter()``` | Retorna um novo RDD somente com o resultado do filtro realizado. | rdd.filter(lambda x: x != 1) | {2, 3, 3}\n",
    "```.distinct()``` | Remove duplicados. | rdd.distinct() | {1, 2, 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map()\n",
    "rdd = sc.parallelize([1,2,3,3])\n",
    "rddResult = rdd.map(lambda x: x * x)\n",
    "for valor in rddResult.collect():\n",
    "    print(valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatMap()\n",
    "rdd = sc.parallelize([1,2,3,3])\n",
    "rdd.flatMap(lambda x: range(x,4)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contador de palavras\n",
    "rddGrafen = sc.parallelize(['Eu estou aprendendo Spark com a Grafen', \n",
    "                            'eu estou gostando das aulas da Grafen', \n",
    "                            'Grafen e top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddQuebraLinha = rddGrafen.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddQuebraLinha.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddPalavraEnumero = rddQuebraLinha.map(lambda palavra: (palavra, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddPalavraEnumero.collect() # poderia ter feito rddPalavraEnumero.take(4) para ver somente 4 palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contador = rddPalavraEnumero.reduceByKey(lambda a,b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contador.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformações básicas que utilizam dois RDD's. Contendo {1, 2, 3} e {3, 4, 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome da função | Propósito | Exemplo | Resultado\n",
    "---- | ----\n",
    "```.union()``` | Produzir um RDD contendo elementos de ambos os RDDs. | rdd.union(other) | {1, 2, 3, 3, 4, 5}\n",
    "```.intersection()``` | RDD contendo apenas elementos encontrados em ambos os RDDs. | rdd.intersection(other) | {3}\n",
    "```.subtract()``` | Remover o conteúdo de um RDD (por exemplo, remover dados de treinamento). | rdd.subtract(other) | {1, 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union(), trazendo rdd somente com os dados entre os dois.\n",
    "rdd1 = sc.parallelize([1,2,3])\n",
    "rdd2 = sc.parallelize([3,4,5])\n",
    "rdd1.union(rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection(), trazendo rdd somente com os dados entre os dois.\n",
    "rdd1 = sc.parallelize([1,2,3])\n",
    "rdd2 = sc.parallelize([3,4,5])\n",
    "rdd1.intersection(rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract(), trazendo rdd somente com os dados entre os dois.\n",
    "rdd1 = sc.parallelize([1,2,3])\n",
    "rdd2 = sc.parallelize([3,4,5])\n",
    "rdd1.subtract(rdd2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome da função | Propósito | Exemplo | Resultado\n",
    "---- | ----\n",
    "```.collect()``` | Retorna todos os elementos de um RDD. | rdd.collect() | {1, 2, 3, 3}\n",
    "```.count()``` | Retorna o número de elementos em um RDD. | rdd.intersection(other) | 4\n",
    "```.countByValue()``` | Retorna número de elementos pela chave. | rdd.countByValue() | {(1, 1), (2, 1), (3, 2)}\n",
    "```.take()``` | Retorna os elementos(n) do RDD. | rdd.subtract(other) | {1, 2}\n",
    "```.top()``` | Retorna os elementos top(n) do RDD | rdd.top(2) | {3, 3}\n",
    "```.reduce()``` | Combina os elementos do RDD juntos em paralelo (por exemplo, soma). | rdd.reduce(lambda x, y: x + y) | 9\n",
    "```.foreach()``` | Aplica a função fornecida a cada elemento do RDD | rdd.foreach(func) | Não se aplica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando .reduce() para trazer a SOMA\n",
    "rdd = sc.parallelize([2,5])\n",
    "rdd.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios: \n",
    "#### *Praticar é a arte do aprender*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Faça um código que exista a entrada de dois números inteiros e exiba a multiplicação deles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([2,5])\n",
    "rdd.reduce(lambda x,y: x*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Faça um código que exiba os valores de um RDD que são maiores que 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 20, 25, 30, 40]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([2,5,10,15,20,25,30,40])\n",
    "rdd.filter(lambda x: x > 10).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Faça um código que exiba os valores de um RDD que são somente impares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 7, 13, 15, 25]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([2,3,5,6,7,10,13,15,20,25,30,40])\n",
    "rdd.filter(lambda x: x % 2 == 1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Faça um código que exiba a soma dos valores dentro de um RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([25,55,1,2,3,4,5,67,100])\n",
    "rdd.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Faça um código que exiba cada elemento do RDD multiplicado por 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100,\n",
       " 500,\n",
       " 700,\n",
       " 1000,\n",
       " 1300,\n",
       " 1500,\n",
       " 2000,\n",
       " 2500,\n",
       " 3000,\n",
       " 2200,\n",
       " 1100,\n",
       " 4400,\n",
       " 5500,\n",
       " 6000]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 5, 7, 10, 13, 15, 20, 25, 30, 22, 11, 44, 55, 60])\n",
    "rdd.map(lambda x: x*100).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Faça um código que leia o arquivo \"sobreRDD.txt\" que foi disponibilizado em aula e conte quantas vezes aparece a palavra \"rdd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('sobreRDD.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddsparklinhas = rdd.filter(lambda linha: 'rdd' in linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Um rdd no spark e simplesmente uma colecao distribuida imutavel de objetos. ',\n",
       " 'Cada rdd e dividido em varias particoes, que podem ser calculadas em diferentes nos do cluster. ',\n",
       " 'Os rdd podem conter qualquer tipo de objetos Python, Java ou Scala, incluindo classes definidas pelo usuario, o spark utiliza rdd para trabalhar com essas estruturas de dados']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddsparklinhas.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddQuebraLinha = rddsparklinhas.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rdd', 4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddQuebraLinha\\\n",
    " .filter(lambda x: x == \"rdd\")\\\n",
    " .map(lambda x: (x, 1))\\\n",
    " .reduceByKey(lambda a,b: a + b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Faça um código que contenha um RDD com as palavras \"rdd\" e \"spark\". \n",
    "\n",
    "    Leia o arquivo \"sobreRDD.txt\" e identifique se o arquivo possui as duas palavras do rdd anterior\n",
    "    \n",
    "    OBS: Quebre cada frase em diversas linhas de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize(['rdd','spark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc.textFile('sobreRDD.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd2.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rdd', 'spark']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.intersection(rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
